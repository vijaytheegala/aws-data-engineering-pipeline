# ğŸš€ AWS Data Engineering Pipeline â€“ Bronzeâ€“Silverâ€“Gold Architecture - Data Modeling
End-to-end AWS Data Engineering project implementing Bronzeâ€“Silverâ€“Gold architecture using Amazon S3, Kinesis, Glue, Databricks, and Redshift for automated data ingestion, transformation, and analytics.

## ğŸ“Œ Overview
This project demonstrates the design and implementation of a **cloud-native data engineering pipeline** on **AWS**, following the **Medallion Architecture (Bronzeâ€“Silverâ€“Gold)** using **Databricks** and AWS services.  
The pipeline automates the process of **data ingestion, transformation, and modeling** for daily e-commerce sales and order analytics.

---

## ğŸ§± Architecture

### ğŸ”¸ Bronze Layer (Raw Zone)
- Ingests data from multiple sources (transactional DBs, APIs, CSVs).
- Stores data **as-is** in **Amazon S3 (Raw Bucket)**.
- AWS Services:
  - Amazon **S3**
  - **Kinesis Data Firehose** (for streaming data)
  - **AWS Glue Crawler** (for schema discovery)

### ğŸ”¸ Silver Layer (Cleansed Zone)
- Cleans and enriches data, removing duplicates and applying transformations.
- Handles **incremental loads**.
- AWS Services:
  - **AWS Glue Jobs / Databricks Notebooks** for ETL
  - **S3 (Processed Zone)**
  - **Delta Lake** for versioning and updates

### ğŸ”¸ Gold Layer (Analytics Zone)
- Creates **business-ready data models** using a **Star Schema**.
- Contains **Dimension** and **Fact** tables:
  - Dimension: Customers, Products, Payments, Region  
  - Fact: Sales
- AWS Services:
  - **Databricks SQL / Delta Tables**
  - **Amazon Redshift / Athena / QuickSight** for analytics and reporting

---

## ğŸ§© Data Flow
Source (Default DB)
â†“
Amazon S3 (Raw Data - Bronze)
â†“
Databricks / Glue Transformations (Silver)
â†“
Databricks SQL / Redshift (Gold)
â†“
QuickSight / Power BI Dashboards




---

## ğŸ“Š Star Schema Data Model

- **Fact Table:** `fact_sales`
  - Contains numeric measures (sales amount, quantity, discount, etc.)
- **Dimension Tables:**  
  - `dim_customers`  
  - `dim_products`  
  - `dim_payments`  
  - `dim_region`

---

## ğŸ§  Key Features

âœ… End-to-end AWS pipeline for ETL automation  
âœ… Incremental data processing in the Silver Layer  
âœ… Star Schema design in the Gold Layer for analytics  
âœ… Integration with Databricks for transformation and Delta Lake for version control  
âœ… Real-time ingestion support via AWS Kinesis  
âœ… Visualization-ready data in Redshift / QuickSight  

---

## ğŸ§° Tech Stack

| Category | Tools / Services |
|-----------|------------------|
| Cloud Platform | **AWS** |
| Storage | **Amazon S3** |
| Data Processing | **Databricks**, **AWS Glue**, **PySpark** |
| Streaming | **AWS Kinesis** |
| Data Modeling | **Delta Lake**, **Amazon Redshift** |
| Visualization | **AWS QuickSight**, **Power BI** |
| Orchestration | **AWS Lambda**, **Glue Workflow**, **Step Functions** |
| Language | **Python**, **SQL** |

---

## ğŸ“ Folder Structure

aws-data-engineering-pipeline/
â”‚
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ 01_default_source/
â”‚   â”œâ”€â”€ sample_data/
â”‚   â”‚   â”œâ”€â”€ customers.csv
â”‚   â”‚   â”œâ”€â”€ products.csv
â”‚   â”‚   â”œâ”€â”€ payments.csv
â”‚   â”‚   â”œâ”€â”€ sales.csv
â”‚   â”‚   â””â”€â”€ regions.csv
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ 02_bronze_layer/
â”‚   â”œâ”€â”€ bronze_ingestion.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ 03_silver_layer/
â”‚   â”œâ”€â”€ silver_transformations.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ 04_gold_layer/
â”‚   â”œâ”€â”€ gold_modeling.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ aws_pipeline_architecture.png   â† (You can add architecture diagram here)
â”‚   â””â”€â”€ datamodel_star_schema.png
â”‚
â””â”€â”€ notebooks/
    â”œâ”€â”€ bronze_to_silver_databricks.ipynb
    â”œâ”€â”€ silver_to_gold_databricks.ipynb
    â””â”€â”€ validations_and_reporting.ipynb


---

## ğŸ§ª Future Enhancements

- Add **Airflow orchestration** for better scheduling and monitoring  
- Integrate **AWS Glue Catalog** with **Athena** for serverless querying  
- Implement **real-time dashboards** via AWS QuickSight  
- Add **CI/CD** for pipeline deployment using **CodePipeline**

---

## ğŸ‘¨â€ğŸ’» Author

**Vijay Kumar Theegala**  
ğŸ“ Data Engineer | Cloud & Big Data Enthusiast  
ğŸ”— [GitHub](https://github.com/vijaytheegala) | [LinkedIn](https://www.linkedin.com/in/vijay-kumar-theegala-69b7bb190)

---

## ğŸ§¾ License
This project is open-source under the [MIT License](LICENSE).

---

## ğŸŒŸ Star the Repo
If you found this project useful, please â­ the repo to show support!

---

## ğŸ§± Example Commands
```bash
# Clone the repository
git clone https://github.com/vijaytheegala/aws-data-engineering-pipeline.git

# Navigate to project directory
cd aws-data-engineering-pipeline

# Run Bronze Layer ingestion
python 02_bronze_layer/bronze_ingestion.py

# Run Silver Layer transformations
python 03_silver_layer/silver_transformations.py

# Run Gold Layer modeling
python 04_gold_layer/gold_modeling.py

